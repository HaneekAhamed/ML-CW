{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_freq_make',\n",
       " 'word_freq_address',\n",
       " 'word_freq_all',\n",
       " 'word_freq_3d',\n",
       " 'word_freq_our',\n",
       " 'word_freq_over',\n",
       " 'word_freq_remove',\n",
       " 'word_freq_internet',\n",
       " 'word_freq_order',\n",
       " 'word_freq_mail',\n",
       " 'word_freq_receive',\n",
       " 'word_freq_will',\n",
       " 'word_freq_people',\n",
       " 'word_freq_report',\n",
       " 'word_freq_addresses',\n",
       " 'word_freq_free',\n",
       " 'word_freq_business',\n",
       " 'word_freq_email',\n",
       " 'word_freq_you',\n",
       " 'word_freq_credit',\n",
       " 'word_freq_your',\n",
       " 'word_freq_font',\n",
       " 'word_freq_000',\n",
       " 'word_freq_money',\n",
       " 'word_freq_hp',\n",
       " 'word_freq_hpl',\n",
       " 'word_freq_george',\n",
       " 'word_freq_650',\n",
       " 'word_freq_lab',\n",
       " 'word_freq_labs',\n",
       " 'word_freq_telnet',\n",
       " 'word_freq_857',\n",
       " 'word_freq_data',\n",
       " 'word_freq_415',\n",
       " 'word_freq_85',\n",
       " 'word_freq_technology',\n",
       " 'word_freq_1999',\n",
       " 'word_freq_parts',\n",
       " 'word_freq_pm',\n",
       " 'word_freq_direct',\n",
       " 'word_freq_cs',\n",
       " 'word_freq_meeting',\n",
       " 'word_freq_original',\n",
       " 'word_freq_project',\n",
       " 'word_freq_re',\n",
       " 'word_freq_edu',\n",
       " 'word_freq_table',\n",
       " 'word_freq_conference',\n",
       " 'char_freq_;',\n",
       " 'char_freq_(',\n",
       " 'char_freq_[',\n",
       " 'char_freq_!',\n",
       " 'char_freq_$',\n",
       " 'char_freq_#',\n",
       " 'capital_run_length_average',\n",
       " 'capital_run_length_longest',\n",
       " 'capital_run_length_total',\n",
       " 'spam_type']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=pd.read_csv('spambase.names', skiprows=32, sep=':\\s+', engine='python', names=['attr',''])\n",
    "names=names['attr']\n",
    "names= list(names)\n",
    "names.append('spam_type')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv('spambase.data', names=names, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0               0.00               0.64           0.64           0.0   \n",
      "1               0.21               0.28           0.50           0.0   \n",
      "2               0.06               0.00           0.71           0.0   \n",
      "3               0.00               0.00           0.00           0.0   \n",
      "4               0.00               0.00           0.00           0.0   \n",
      "...              ...                ...            ...           ...   \n",
      "4596            0.31               0.00           0.62           0.0   \n",
      "4597            0.00               0.00           0.00           0.0   \n",
      "4598            0.30               0.00           0.30           0.0   \n",
      "4599            0.96               0.00           0.00           0.0   \n",
      "4600            0.00               0.00           0.65           0.0   \n",
      "\n",
      "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0              0.32            0.00              0.00                0.00   \n",
      "1              0.14            0.28              0.21                0.07   \n",
      "2              1.23            0.19              0.19                0.12   \n",
      "3              0.63            0.00              0.31                0.63   \n",
      "4              0.63            0.00              0.31                0.63   \n",
      "...             ...             ...               ...                 ...   \n",
      "4596           0.00            0.31              0.00                0.00   \n",
      "4597           0.00            0.00              0.00                0.00   \n",
      "4598           0.00            0.00              0.00                0.00   \n",
      "4599           0.32            0.00              0.00                0.00   \n",
      "4600           0.00            0.00              0.00                0.00   \n",
      "\n",
      "      word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
      "0                0.00            0.00  ...        0.000        0.000   \n",
      "1                0.00            0.94  ...        0.000        0.132   \n",
      "2                0.64            0.25  ...        0.010        0.143   \n",
      "3                0.31            0.63  ...        0.000        0.137   \n",
      "4                0.31            0.63  ...        0.000        0.135   \n",
      "...               ...             ...  ...          ...          ...   \n",
      "4596             0.00            0.00  ...        0.000        0.232   \n",
      "4597             0.00            0.00  ...        0.000        0.000   \n",
      "4598             0.00            0.00  ...        0.102        0.718   \n",
      "4599             0.00            0.00  ...        0.000        0.057   \n",
      "4600             0.00            0.00  ...        0.000        0.000   \n",
      "\n",
      "      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "0             0.0        0.778        0.000        0.000   \n",
      "1             0.0        0.372        0.180        0.048   \n",
      "2             0.0        0.276        0.184        0.010   \n",
      "3             0.0        0.137        0.000        0.000   \n",
      "4             0.0        0.135        0.000        0.000   \n",
      "...           ...          ...          ...          ...   \n",
      "4596          0.0        0.000        0.000        0.000   \n",
      "4597          0.0        0.353        0.000        0.000   \n",
      "4598          0.0        0.000        0.000        0.000   \n",
      "4599          0.0        0.000        0.000        0.000   \n",
      "4600          0.0        0.125        0.000        0.000   \n",
      "\n",
      "      capital_run_length_average  capital_run_length_longest  \\\n",
      "0                          3.756                          61   \n",
      "1                          5.114                         101   \n",
      "2                          9.821                         485   \n",
      "3                          3.537                          40   \n",
      "4                          3.537                          40   \n",
      "...                          ...                         ...   \n",
      "4596                       1.142                           3   \n",
      "4597                       1.555                           4   \n",
      "4598                       1.404                           6   \n",
      "4599                       1.147                           5   \n",
      "4600                       1.250                           5   \n",
      "\n",
      "      capital_run_length_total  spam_type  \n",
      "0                          278          1  \n",
      "1                         1028          1  \n",
      "2                         2259          1  \n",
      "3                          191          1  \n",
      "4                          191          1  \n",
      "...                        ...        ...  \n",
      "4596                        88          0  \n",
      "4597                        14          0  \n",
      "4598                       118          0  \n",
      "4599                        78          0  \n",
      "4600                        40          0  \n",
      "\n",
      "[4601 rows x 58 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cleaning data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop(columns=['spam_type'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataframe['spam_type']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "scaled_data = scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "x_pca = pca.fit_transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit(scaled_data)\n",
    "X_test_pca = pca.fit(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca = pca.transform(scaled_data)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(scaled_data.shape)\n",
    "print(x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(x_pca[:,0],x_pca[:,1], c= Y_train)\n",
    "plt.xlabel('1st pca component')\n",
    "plt.ylabel('2nd pca component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_X=StandardScaler()\n",
    "X_train = stand_X.fit_transform(X_train)\n",
    "X_test = stand_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(math.sqrt(len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_pca, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict= classi.predict(X_test)\n",
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pca_predict =knn.predict(X_test_pca)\n",
    "y_pca_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test,Y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cm = confusion_matrix(Y_test,y_pca_predict)\n",
    "print(pca_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm/np.sum(cm), annot=True,\n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_f1Score = f1_score(Y_test,Y_predict)\n",
    "knn_f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pca_f1Score = f1_score(Y_test,y_pca_predict)\n",
    "knn_pca_f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy = accuracy_score(Y_test,Y_predict)\n",
    "knn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pca_accuracy = accuracy_score(Y_test,y_pca_predict)\n",
    "knn_pca_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_classi = DecisionTreeClassifier(criterion='entropy', random_state=1, max_depth=29, min_samples_leaf=57)\n",
    "DT_classi.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Y_predict = DT_classi.predict(X_test)\n",
    "DT_Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_cm = confusion_matrix(Y_test,DT_Y_predict)\n",
    "print(DT_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(DT_cm/np.sum(DT_cm), annot=True,\n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_f1Score = f1_score(Y_test,DT_Y_predict)\n",
    "DT_f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_accuracy = accuracy_score(Y_test,DT_Y_predict)\n",
    "DT_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN f1 Score ::',knn_f1Score)\n",
    "print('KNN accuracy ::',knn_accuracy)\n",
    "print('\\n')\n",
    "print('Decision Tree f1 Score:: ',DT_f1Score)\n",
    "print('Decision Tree accuracy score:: ',DT_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
